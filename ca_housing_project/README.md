# California Housing Project (Chapter 2)

This repository contains an end-to-end workflow for analyzing and modeling the California Housing dataset.

## Directory Structure

data/
    raw/ → original housing.csv (never modified)
    train/ → 13-column raw train split & 24-feature processed train
    test/ → 13-column raw test split
images/ → plots generated by analysis notebooks
analysis/
    ida.ipynb → Initial Data Analysis (stratified split)
    eda.ipynb → Exploratory Data Analysis (visualizations + feature engineering)
    preprocessing_pipeline.py → CLI script for preprocessing (24 features)
models/
    LinearRegression.ipynb
    DecisionTree.ipynb
    RandomForest.ipynb
    SVR.ipynb
README.md


## Workflow
1. **Initial Data Analysis (IDA)**  
   Run `analysis/ida.ipynb`  
   Saves:  
   - `data/train/housing_train.csv` (13 columns)  
   - `data/test/housing_test.csv` (13 columns)  
   - Keeps raw `data/raw/housing.csv` untouched  

2. **Exploratory Data Analysis (EDA)**  
   Run `analysis/eda.ipynb` or execute the script `analysis/preprocessing_pipeline.py`  
   Saves:  
   - `data/train/housing_train_processed.csv` (24 engineered features + target)  
   - Visualization plots in `/images`  

3. **Model Training**  
   Run any notebook in `/models`:  
   - `LinearRegression.ipynb`  
   - `DecisionTree.ipynb`  
   - `RandomForest.ipynb`  
   - `SVR.ipynb`  

   Each notebook includes:  
   - **# Data Loading** (processed dataset)  
   - **# Model Fitting**  
   - **# Cross-Validation**  
   - **# Hyperparameter Tuning**  
   - **# Model Saving**  

   Trained models are saved as `.pkl` files into `/models`.

---

## Requirements

- See `requirements.txt` for dependencies (scikit-learn, pandas, numpy, matplotlib, joblib, etc.)  

Install with:
```bash
pip install -r requirements.txt


